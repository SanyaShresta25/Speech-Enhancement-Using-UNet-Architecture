{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanyaShresta25/Speech-Enhancement-Using-UNet-Architecture/blob/main/SpeechEnhancementUsingUNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Clone the Repo**"
      ],
      "metadata": {
        "id": "ScT254n6nTVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dathu/Speech-enhancement-deeplearn-vbelz.git\n",
        "%cd Speech-enhancement-deeplearn-vbelz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChS9HQ1mnWDG",
        "outputId": "f69b4716-eba1-4be0-f2d4-17011f826146"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Speech-enhancement-deeplearn-vbelz'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 157 (delta 35), reused 31 (delta 31), pack-reused 117 (from 1)\u001b[K\n",
            "Receiving objects: 100% (157/157), 47.19 MiB | 15.66 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n",
            "/content/Speech-enhancement-deeplearn-vbelz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Requirements**"
      ],
      "metadata": {
        "id": "h6rte-OBnhXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update all requirements to more recent versions\n",
        "!sed -i 's/tensorflow==1.15.2/tensorflow>=2.10.0/g' requirements.txt\n",
        "!sed -i 's/scipy==1.3.1/scipy>=1.7.0/g' requirements.txt\n",
        "!sed -i 's/matplotlib==3.1.1/matplotlib>=3.5.0/g' requirements.txt\n",
        "!sed -i 's/numpy==1.17.2/numpy>=1.20.0/g' requirements.txt\n",
        "!sed -i 's/librosa==0.7.0/librosa>=0.9.0/g' requirements.txt\n",
        "!sed -i 's/sklearn/scikit-learn/g' requirements.txt\n",
        "\n",
        "# Install the updated requirements\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4pzsBAOnkdt",
        "outputId": "976126f6-3e0a-4ddb-c24d-707732ef9d5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytest in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (8.3.5)\n",
            "Requirement already satisfied: tensorflow>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.6.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest->-r requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (0.60.0)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 3)) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 3)) (4.3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa->-r requirements.txt (line 3)) (1.17.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 3)) (2.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.10.0->-r requirements.txt (line 2)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Speech Data Preparation**"
      ],
      "metadata": {
        "id": "2QHTt9HonLWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xpRvFnGKnFBO",
        "outputId": "9a696b3c-d206-4954-d22c-cd5e433d9c08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=96a8c480de74e36f876f1044b9c331276fe371e485650a80ab2b1c0b3671cc26\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b3/0f/a40dbd1c6861731779f62cc4babcb234387e11d697df70ee97\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "\n",
            "ğŸ”§ Processing Training Set...\n",
            "[Train] Processed 0 files\n",
            "[Train] Processed 10 files\n",
            "[Train] Processed 20 files\n",
            "[Train] Processed 30 files\n",
            "[Train] Processed 40 files\n",
            "[Train] Processed 50 files\n",
            "[Train] Processed 60 files\n",
            "[Train] Processed 70 files\n",
            "[Train] Processed 80 files\n",
            "[Train] Processed 90 files\n",
            "\n",
            "ğŸ”§ Processing Test Set...\n",
            "[Test] Processed 0 files\n",
            "[Test] Processed 10 files\n",
            "[Test] Processed 20 files\n",
            "[Test] Processed 30 files\n",
            "[Test] Processed 40 files\n",
            "\n",
            "âœ… Data preparation complete!\n"
          ]
        }
      ],
      "source": [
        "## ğŸ§© Step 1: Install Required Libraries\n",
        "!pip install librosa soundfile wget\n",
        "\n",
        "## ğŸ“ Step 2: Setup Directory Structure\n",
        "import os\n",
        "\n",
        "base_dirs = ['Train', 'Test']\n",
        "sub_dirs = ['clean_voice', 'noise', 'sound', 'spectrogram', 'time_serie']\n",
        "\n",
        "for base in base_dirs:\n",
        "    for sub in sub_dirs:\n",
        "        os.makedirs(os.path.join(base, sub), exist_ok=True)\n",
        "\n",
        "## ğŸ“¦ Step 3: Download Datasets (LibriSpeech dev-clean & ESC-50)\n",
        "import wget\n",
        "\n",
        "# LibriSpeech\n",
        "librispeech_url = 'http://www.openslr.org/resources/12/dev-clean.tar.gz'\n",
        "esc50_url = 'https://github.com/karoldvl/ESC-50/archive/master.zip'\n",
        "\n",
        "wget.download(librispeech_url, 'dev-clean.tar.gz')\n",
        "wget.download(esc50_url, 'ESC-50.zip')\n",
        "\n",
        "## ğŸ“‚ Step 4: Extract Datasets\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "with tarfile.open('dev-clean.tar.gz', 'r:gz') as tar:\n",
        "    tar.extractall('.')\n",
        "\n",
        "with zipfile.ZipFile('ESC-50.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "## ğŸ§ Step 5: Process and Convert Audio Files\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import random\n",
        "\n",
        "# Paths\n",
        "clean_path = './LibriSpeech/dev-clean'\n",
        "noise_path = './ESC-50-master/audio'\n",
        "\n",
        "# Collect files\n",
        "clean_files = [f for f in glob(f'{clean_path}/**/*.flac', recursive=True)]\n",
        "noise_files = glob(f'{noise_path}/*.wav')\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Split into Train and Test\n",
        "train_clean = clean_files[:100]\n",
        "test_clean = clean_files[100:150]\n",
        "\n",
        "train_noise = noise_files[:50]\n",
        "test_noise = noise_files[50:75]\n",
        "\n",
        "# Utility: Create noisy mixture\n",
        "def mix_audio(clean, noise, snr):\n",
        "    clean_power = np.mean(clean**2)\n",
        "    noise_power = np.mean(noise**2)\n",
        "    scale = np.sqrt(clean_power / (10**(snr / 10) * noise_power))\n",
        "    return clean + scale * noise\n",
        "\n",
        "# Processing function\n",
        "def process_set(clean_list, noise_list, set_type):\n",
        "    for i, clean_file in enumerate(clean_list):\n",
        "        clean, sr = librosa.load(clean_file, sr=16000)\n",
        "\n",
        "        noise_file = np.random.choice(noise_list)\n",
        "        noise, _ = librosa.load(noise_file, sr=16000)\n",
        "\n",
        "        if len(noise) < len(clean):\n",
        "            noise = np.tile(noise, int(np.ceil(len(clean)/len(noise))))\n",
        "        noise = noise[:len(clean)]\n",
        "\n",
        "        snr = np.random.uniform(0, 10)\n",
        "        noisy = mix_audio(clean, noise, snr)\n",
        "\n",
        "        clean_out = f\"{set_type}/clean_voice/clean_{i:04d}.wav\"\n",
        "        noise_out = f\"{set_type}/noise/noise_{i:04d}.wav\"\n",
        "        noisy_out = f\"{set_type}/sound/noisy_{i:04d}.wav\"\n",
        "\n",
        "        sf.write(clean_out, clean, sr)\n",
        "        sf.write(noise_out, noise, sr)\n",
        "        sf.write(noisy_out, noisy, sr)\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(f\"[{set_type}] Processed {i} files\")\n",
        "\n",
        "print(\"\\nğŸ”§ Processing Training Set...\")\n",
        "process_set(train_clean, train_noise, 'Train')\n",
        "\n",
        "print(\"\\nğŸ”§ Processing Test Set...\")\n",
        "process_set(test_clean, test_noise, 'Test')\n",
        "\n",
        "print(\"\\nâœ… Data preparation complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python prepare_data.py"
      ],
      "metadata": {
        "id": "qvGvakLRq0Ng"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Creation**"
      ],
      "metadata": {
        "id": "SSUkZiFupojJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azG5JuR_tGUq",
        "outputId": "beec2e4e-e816-414d-a06e-12727f4dc736"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (2.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --mode data_creation \\\n",
        "  --noise_dir ./Train/noise \\\n",
        "  --voice_dir ./Train/clean_voice \\\n",
        "  --path_save_spectrogram ./Train/spectrogram/ \\\n",
        "  --path_save_time_serie ./Train/time_serie/ \\\n",
        "  --path_save_sound ./Train/sound/ \\\n",
        "  --nb_samples 200\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7fZi-gVrM8N",
        "outputId": "550e7f25-0284-444f-8eef-9ce2207fbca6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-23 12:01:33.450641: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745409693.485980    4810 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745409693.497016    4810 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-23 12:01:33.534857: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training**"
      ],
      "metadata": {
        "id": "8g7YagsYzJkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --mode training \\\n",
        "  --weights_folder ./weights \\\n",
        "  --training_from_scratch True \\\n",
        "  --epochs 30 \\\n",
        "  --batch_size 16 \\\n",
        "  --name_model model_unet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-iro1U4uAJM",
        "outputId": "27a94202-b5be-404c-eb71-71620260d57f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-23 12:03:15.108352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745409795.140187    5258 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745409795.150062    5258 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-23 12:03:15.180477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "DescribeResult(nobs=3276800, minmax=(array([-80.]), array([0.])), mean=array([-41.43137509]), variance=array([256.88213573]), skewness=array([-0.32026139]), kurtosis=array([-0.2641849]))\n",
            "DescribeResult(nobs=3276800, minmax=(array([-68.61741356]), array([79.37810602])), mean=array([8.41081566]), variance=array([205.19349943]), skewness=array([1.13781155]), kurtosis=array([0.90781728]))\n",
            "(200, 128, 128)\n",
            "(200, 128, 128)\n",
            "DescribeResult(nobs=3276800, minmax=(array([-0.68]), array([0.92])), mean=array([0.0913725]), variance=array([0.10275285]), skewness=array([-0.32026139]), kurtosis=array([-0.2641849]))\n",
            "DescribeResult(nobs=3276800, minmax=(array([-0.90996846]), array([0.89485495])), mean=array([0.02940019]), variance=array([0.03051658]), skewness=array([1.13781155]), kurtosis=array([0.90781728]))\n",
            "2025-04-23 12:03:19.947067: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1745409799.949180    5258 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\u001b[1mModel: \"functional\"\u001b[0m\n",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
            "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
            "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
            "â”‚ input_layer         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ -                 â”‚\n",
            "â”‚ (\u001b[94mInputLayer\u001b[0m)        â”‚ \u001b[32m1\u001b[0m)                â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d (\u001b[94mConv2D\u001b[0m)     â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚        \u001b[32m160\u001b[0m â”‚ input_layer[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] â”‚\n",
            "â”‚                     â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ conv2d[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_1 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚      \u001b[32m2,320\u001b[0m â”‚ leaky_re_lu[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] â”‚\n",
            "â”‚                     â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_1       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_1[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚ (\u001b[94mMaxPooling2D\u001b[0m)      â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_2 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚      \u001b[32m4,640\u001b[0m â”‚ max_pooling2d[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_2       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_3 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚      \u001b[32m9,248\u001b[0m â”‚ leaky_re_lu_2[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_3       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_1     â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_3[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚ (\u001b[94mMaxPooling2D\u001b[0m)      â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_4 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚     \u001b[32m18,496\u001b[0m â”‚ max_pooling2d_1[\u001b[32mâ€¦\u001b[0m â”‚\n",
            "â”‚                     â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_4       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_5 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚     \u001b[32m36,928\u001b[0m â”‚ leaky_re_lu_4[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_5       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_2     â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_5[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚ (\u001b[94mMaxPooling2D\u001b[0m)      â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_6 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚     \u001b[32m73,856\u001b[0m â”‚ max_pooling2d_2[\u001b[32mâ€¦\u001b[0m â”‚\n",
            "â”‚                     â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_6       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_7 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚    \u001b[32m147,584\u001b[0m â”‚ leaky_re_lu_6[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_7       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout (\u001b[94mDropout\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_7[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ max_pooling2d_3     â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m128\u001b[0m) â”‚          \u001b[32m0\u001b[0m â”‚ dropout[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     â”‚\n",
            "â”‚ (\u001b[94mMaxPooling2D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_8 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m256\u001b[0m) â”‚    \u001b[32m295,168\u001b[0m â”‚ max_pooling2d_3[\u001b[32mâ€¦\u001b[0m â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_8       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m256\u001b[0m) â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_9 (\u001b[94mConv2D\u001b[0m)   â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m256\u001b[0m) â”‚    \u001b[32m590,080\u001b[0m â”‚ leaky_re_lu_8[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_9       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m256\u001b[0m) â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ dropout_1 (\u001b[94mDropout\u001b[0m) â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m8\u001b[0m, \u001b[32m256\u001b[0m) â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_9[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ up_sampling2d       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ dropout_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mUpSampling2D\u001b[0m)      â”‚ \u001b[32m256\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_10 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚    \u001b[32m131,200\u001b[0m â”‚ up_sampling2d[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_10      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ concatenate         â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ dropout[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],    â”‚\n",
            "â”‚ (\u001b[94mConcatenate\u001b[0m)       â”‚ \u001b[32m256\u001b[0m)              â”‚            â”‚ leaky_re_lu_10[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_11 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚    \u001b[32m295,040\u001b[0m â”‚ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] â”‚\n",
            "â”‚                     â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_11      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_12 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚    \u001b[32m147,584\u001b[0m â”‚ leaky_re_lu_11[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_12      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m16\u001b[0m, \u001b[32m16\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ up_sampling2d_1     â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_12[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚ (\u001b[94mUpSampling2D\u001b[0m)      â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_13 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚     \u001b[32m32,832\u001b[0m â”‚ up_sampling2d_1[\u001b[32mâ€¦\u001b[0m â”‚\n",
            "â”‚                     â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_13      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ concatenate_1       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_5[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚ (\u001b[94mConcatenate\u001b[0m)       â”‚ \u001b[32m128\u001b[0m)              â”‚            â”‚ leaky_re_lu_13[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_14 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚     \u001b[32m73,792\u001b[0m â”‚ concatenate_1[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_14      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_15 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚     \u001b[32m36,928\u001b[0m â”‚ leaky_re_lu_14[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_15      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m32\u001b[0m, \u001b[32m32\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ up_sampling2d_2     â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_15[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚ (\u001b[94mUpSampling2D\u001b[0m)      â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_16 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚      \u001b[32m8,224\u001b[0m â”‚ up_sampling2d_2[\u001b[32mâ€¦\u001b[0m â”‚\n",
            "â”‚                     â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_16      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ concatenate_2       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_3[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚ (\u001b[94mConcatenate\u001b[0m)       â”‚ \u001b[32m64\u001b[0m)               â”‚            â”‚ leaky_re_lu_16[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_17 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚     \u001b[32m18,464\u001b[0m â”‚ concatenate_2[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_17      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_18 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚      \u001b[32m9,248\u001b[0m â”‚ leaky_re_lu_17[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_18      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m64\u001b[0m, \u001b[32m64\u001b[0m,    â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ up_sampling2d_3     â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_18[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚ (\u001b[94mUpSampling2D\u001b[0m)      â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_19 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚      \u001b[32m2,064\u001b[0m â”‚ up_sampling2d_3[\u001b[32mâ€¦\u001b[0m â”‚\n",
            "â”‚                     â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_19      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_19[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ concatenate_3       â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ leaky_re_lu_1[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚ (\u001b[94mConcatenate\u001b[0m)       â”‚ \u001b[32m32\u001b[0m)               â”‚            â”‚ leaky_re_lu_19[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_20 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚      \u001b[32m4,624\u001b[0m â”‚ concatenate_3[\u001b[32m0\u001b[0m]â€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_20      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_20[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_21 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚      \u001b[32m2,320\u001b[0m â”‚ leaky_re_lu_20[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_21      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_21[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m16\u001b[0m)               â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_22 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚        \u001b[32m290\u001b[0m â”‚ leaky_re_lu_21[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m2\u001b[0m)                â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ leaky_re_lu_22      â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m0\u001b[0m â”‚ conv2d_22[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   â”‚\n",
            "â”‚ (\u001b[94mLeakyReLU\u001b[0m)         â”‚ \u001b[32m2\u001b[0m)                â”‚            â”‚                   â”‚\n",
            "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
            "â”‚ conv2d_23 (\u001b[94mConv2D\u001b[0m)  â”‚ (\u001b[96mNone\u001b[0m, \u001b[32m128\u001b[0m, \u001b[32m128\u001b[0m,  â”‚          \u001b[32m3\u001b[0m â”‚ leaky_re_lu_22[\u001b[32m0\u001b[0mâ€¦ â”‚\n",
            "â”‚                     â”‚ \u001b[32m1\u001b[0m)                â”‚            â”‚                   â”‚\n",
            "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\u001b[1m Total params: \u001b[0m\u001b[32m1,941,093\u001b[0m (7.40 MB)\n",
            "\u001b[1m Trainable params: \u001b[0m\u001b[32m1,941,093\u001b[0m (7.40 MB)\n",
            "\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n",
            "Epoch 1/30\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1745409807.789057    5307 service.cc:148] XLA service 0x7ac240005780 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1745409807.789166    5307 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2025-04-23 12:03:28.043725: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1745409808.994969    5307 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
            "2025-04-23 12:03:30.130020: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,16,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,1,128,128]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.362482: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,16,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,128,128]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.584311: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,16,64,64]{3,2,1,0}, f32[32,16,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.649341: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,64,64]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.735617: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,32,32]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.784730: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,32,32]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.846136: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,16,16]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.893157: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,16,16]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:30.951478: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,256,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,8,8]{3,2,1,0}, f32[256,128,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:31.003879: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,256,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,8,8]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:31.122588: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,256,16,16]{3,2,1,0}, f32[128,256,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:31.242551: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,128,32,32]{3,2,1,0}, f32[64,128,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:31.420231: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,64,64,64]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:31.652550: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[16,16,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,128,128]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "I0000 00:00:1745409819.485251    5307 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m10/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 0.2467 - mae: 0.37252025-04-23 12:03:41.478687: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,16,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,1,128,128]{3,2,1,0}, f32[16,1,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.517668: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,16,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,16,128,128]{3,2,1,0}, f32[16,16,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.579497: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,16,64,64]{3,2,1,0}, f32[32,16,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.611708: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,64,64]{3,2,1,0}, f32[32,32,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.673763: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,32,32]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.705053: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,32,32]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.758751: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,16,16]{3,2,1,0}, f32[128,64,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.800512: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,16,16]{3,2,1,0}, f32[128,128,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.847492: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,256,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,8,8]{3,2,1,0}, f32[256,128,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.895890: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,256,8,8]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,8,8]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}, f32[256]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:41.984711: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,128,16,16]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,256,16,16]{3,2,1,0}, f32[128,256,3,3]{3,2,1,0}, f32[128]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:42.054654: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,64,32,32]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,128,32,32]{3,2,1,0}, f32[64,128,3,3]{3,2,1,0}, f32[64]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:42.168370: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,32,64,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,64,64,64]{3,2,1,0}, f32[32,64,3,3]{3,2,1,0}, f32[32]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "2025-04-23 12:03:42.296123: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:557] Omitted potentially buggy algorithm eng14{k25=0} for conv (f32[4,16,128,128]{3,2,1,0}, u8[0]{0}) custom-call(f32[4,32,128,128]{3,2,1,0}, f32[16,32,3,3]{3,2,1,0}, f32[16]{0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]}\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - loss: 0.2286 - mae: 0.3518\n",
            "Epoch 1: val_loss improved from inf to 0.02501, saving model to ./weights/model_best.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1s/step - loss: 0.2215 - mae: 0.3437 - val_loss: 0.0250 - val_mae: 0.1170\n",
            "Epoch 2/30\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0370 - mae: 0.1493\n",
            "Epoch 2: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 51ms/step - loss: 0.0368 - mae: 0.1490 - val_loss: 0.0270 - val_mae: 0.1352\n",
            "Epoch 3/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0497 - mae: 0.1663\n",
            "Epoch 3: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0478 - mae: 0.1627 - val_loss: 0.1347 - val_mae: 0.2948\n",
            "Epoch 4/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0258 - mae: 0.1239\n",
            "Epoch 4: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0261 - mae: 0.1248 - val_loss: 0.0253 - val_mae: 0.1180\n",
            "Epoch 5/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0270 - mae: 0.1278\n",
            "Epoch 5: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0270 - mae: 0.1280 - val_loss: 0.0445 - val_mae: 0.1806\n",
            "Epoch 6/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0255 - mae: 0.1238\n",
            "Epoch 6: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0255 - mae: 0.1237 - val_loss: 0.1125 - val_mae: 0.2870\n",
            "Epoch 7/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0262 - mae: 0.1255\n",
            "Epoch 7: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0261 - mae: 0.1254 - val_loss: 0.0440 - val_mae: 0.1671\n",
            "Epoch 8/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0264 - mae: 0.1260\n",
            "Epoch 8: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0262 - mae: 0.1254 - val_loss: 0.0684 - val_mae: 0.2176\n",
            "Epoch 9/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0252 - mae: 0.1233\n",
            "Epoch 9: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0250 - mae: 0.1228 - val_loss: 0.0475 - val_mae: 0.1813\n",
            "Epoch 10/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0234 - mae: 0.1173\n",
            "Epoch 10: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0235 - mae: 0.1175 - val_loss: 0.0331 - val_mae: 0.1487\n",
            "Epoch 11/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0253 - mae: 0.1198\n",
            "Epoch 11: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0251 - mae: 0.1196 - val_loss: 0.0310 - val_mae: 0.1414\n",
            "Epoch 12/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0256 - mae: 0.1220\n",
            "Epoch 12: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0253 - mae: 0.1212 - val_loss: 0.0368 - val_mae: 0.1618\n",
            "Epoch 13/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0221 - mae: 0.1144\n",
            "Epoch 13: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0222 - mae: 0.1146 - val_loss: 0.0637 - val_mae: 0.2174\n",
            "Epoch 14/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0226 - mae: 0.1148\n",
            "Epoch 14: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0225 - mae: 0.1146 - val_loss: 0.0648 - val_mae: 0.2202\n",
            "Epoch 15/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0217 - mae: 0.1122\n",
            "Epoch 15: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0216 - mae: 0.1119 - val_loss: 0.0858 - val_mae: 0.2573\n",
            "Epoch 16/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0213 - mae: 0.1110\n",
            "Epoch 16: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0213 - mae: 0.1109 - val_loss: 0.0403 - val_mae: 0.1680\n",
            "Epoch 17/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0206 - mae: 0.1091\n",
            "Epoch 17: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0206 - mae: 0.1091 - val_loss: 0.0999 - val_mae: 0.2769\n",
            "Epoch 18/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0199 - mae: 0.1068\n",
            "Epoch 18: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0200 - mae: 0.1070 - val_loss: 0.0402 - val_mae: 0.1547\n",
            "Epoch 19/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0197 - mae: 0.1046\n",
            "Epoch 19: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0199 - mae: 0.1052 - val_loss: 0.0353 - val_mae: 0.1553\n",
            "Epoch 20/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0214 - mae: 0.1100\n",
            "Epoch 20: val_loss did not improve from 0.02501\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0212 - mae: 0.1095 - val_loss: 0.0688 - val_mae: 0.2224\n",
            "Epoch 21/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0211 - mae: 0.1102\n",
            "Epoch 21: val_loss improved from 0.02501 to 0.01828, saving model to ./weights/model_best.h5\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0214 - mae: 0.1106 - val_loss: 0.0183 - val_mae: 0.1024\n",
            "Epoch 22/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0234 - mae: 0.1155\n",
            "Epoch 22: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0233 - mae: 0.1152 - val_loss: 0.0242 - val_mae: 0.1278\n",
            "Epoch 23/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0215 - mae: 0.1122\n",
            "Epoch 23: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0214 - mae: 0.1121 - val_loss: 0.0491 - val_mae: 0.1811\n",
            "Epoch 24/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0205 - mae: 0.1101\n",
            "Epoch 24: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0205 - mae: 0.1098 - val_loss: 0.0486 - val_mae: 0.1813\n",
            "Epoch 25/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0209 - mae: 0.1105\n",
            "Epoch 25: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0207 - mae: 0.1098 - val_loss: 0.0511 - val_mae: 0.1847\n",
            "Epoch 26/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0191 - mae: 0.1037\n",
            "Epoch 26: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0191 - mae: 0.1038 - val_loss: 0.0954 - val_mae: 0.2622\n",
            "Epoch 27/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0170 - mae: 0.0978\n",
            "Epoch 27: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0173 - mae: 0.0986 - val_loss: 0.0713 - val_mae: 0.2233\n",
            "Epoch 28/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0177 - mae: 0.1005\n",
            "Epoch 28: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0177 - mae: 0.1007 - val_loss: 0.1001 - val_mae: 0.2647\n",
            "Epoch 29/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0190 - mae: 0.1052\n",
            "Epoch 29: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0189 - mae: 0.1047 - val_loss: 0.0588 - val_mae: 0.1891\n",
            "Epoch 30/30\n",
            "\u001b[1m11/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0188 - mae: 0.1027\n",
            "Epoch 30: val_loss did not improve from 0.01828\n",
            "\u001b[1m12/12\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0188 - mae: 0.1027 - val_loss: 0.0358 - val_mae: 0.1417\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction**"
      ],
      "metadata": {
        "id": "_GZCUiN9zbxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py \\\n",
        "  --mode prediction \\\n",
        "  --weights_folder ./weights \\\n",
        "  --name_model model_unet \\\n",
        "  --audio_dir_prediction ./demo_data/test \\\n",
        "  --dir_save_prediction ./demo_data/save_predictions \\\n",
        "  --audio_input_prediction [\"noisy_sample.wav\"] \\\n",
        "  --audio_output_prediction denoised_sample.wav\n"
      ],
      "metadata": {
        "id": "-9fRU6AFxwsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/Speech-enhancement-deeplearn-vbelz/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldJEuxoUs-oR",
        "outputId": "d2d8dd00-c61a-430d-bc66-e3af2a1d1a2a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args.py\t\t dev-clean.tar.gz  main.py\t\t  requirements.txt\n",
            "AUTHORS.rst\t ESC-50-master\t   model_unet.py\t  Test\n",
            "colab\t\t ESC-50.zip\t   prediction_denoise.py  tests\n",
            "data_display.py  img\t\t   prepare_data.py\t  Train\n",
            "data_tools.py\t LibriSpeech\t   __pycache__\t\t  train_model.py\n",
            "demo_data\t LICENSE\t   README.md\t\t  weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import os\n",
        "print(os.path.exists('/content/Speech-enhancement-deeplearn-vbelz/weights'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLymJi_oKh26",
        "outputId": "cffa4bca-6301-49b6-8803-fab6027df8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "weights_path = '/content/Speech-enhancement-deeplearn-vbelz/weights'\n",
        "name_model = 'model_unet'\n",
        "weights_file = f\"{weights_path}/{name_model}.h5\"\n",
        "\n",
        "print(\"Exists:\", os.path.exists(weights_file))\n",
        "print(\"Expected file path:\", weights_file)\n"
      ],
      "metadata": {
        "id": "inX8Bd4PQnpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7ed8f5-c2c5-40a2-8efd-2498aeee8d74"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists: True\n",
            "Expected file path: /content/Speech-enhancement-deeplearn-vbelz/weights/model_unet.h5\n"
          ]
        }
      ]
    }
  ]
}